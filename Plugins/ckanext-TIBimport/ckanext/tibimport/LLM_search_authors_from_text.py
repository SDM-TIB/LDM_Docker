from ckan.common import config
import os, requests, json


class LLMSearchAuthorsFromText():

    def __init__(self):

        self.API_key = config.get('OPENAI_API_KEY', "")
        self.this_file_path = os.path.dirname(os.path.abspath(__file__))
        self.openIA_url = 'https://api.openai.com/v1/chat/completions'
        self.prompt_file_path = os.path.join(self.this_file_path, 'Authors_No_Middle_prompt.txt')

    def _config_request(self):

        # Set the request headers including the Authorization header with the API key
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.API_key}'
        }

        # model 'o1-mini' 65k output
        # model 'gpt-4o-2024-08-06' 16k but supports structured output
        # Prepare the data payload
        data = {
            "model": "o1-mini",
            # "temperature": 0,
            "messages": [
                {"role": "user", "content": ""},
            ]
        }
        return {"headers": headers, "data": data}

    def call_llm_api(self, prompt):
        """
        Sends the input prompt to the GPT-4 model via a direct HTTP POST request and returns the assistant's response.

        Parameters:
        - prompt (str): The user's input prompt.

        Returns:
        - str: The assistant's response generated by GPT-4.
        """

        # Check API key from CKAN config
        if not self.API_key:
            raise ValueError(
                "Error: The OpenAI API key is not set. Please set it as an environment variable 'OPENAI_API_KEY'.")

        call_data = self._config_request()
        # set prompt
        call_data["data"]["messages"][0]["content"] = prompt

        # Make the POST request to the OpenAI API endpoint
        try:
            response = requests.post(self.openIA_url, headers=call_data["headers"], json=call_data["data"])
            response.raise_for_status()  # Raise an error for bad status codes

            # Parse the response JSON and extract the assistant's reply
            content = response.json()['choices'][0]['message']['content']
            return content

        except requests.exceptions.HTTPError as http_err:
            raise RuntimeError(f"HTTP error occurred: {http_err} - {response.text}")
            return ""
        except Exception as err:
            raise RuntimeError(f"An error occurred: {err}")
            return ""

    def _read_prompt_context(self):
        # Read the prompt file content
        try:
            with open(self.prompt_file_path, 'r', encoding='utf-8') as prompt_file:
                return prompt_file.read()
        except Exception as e:
            print(f"Error reading prompt file: {e}")
            return ""
    def _adjust_result(self, call_result):

        authors = []

        res_aux = call_result[next(iter(call_result))]
        # call_result.get('entry1', [])
        if not res_aux:
            res_aux = call_result.get()
        # Result could be a list:
        #  {'entry1': [{'firstName': 'Marco', 'lastName': 'Gutfleisch'}, {'firstName': 'Mauricio', 'lastName': 'Brunet'}]}
        if isinstance(res_aux, list):
            for author in res_aux:
                authors.append(author)
        # Result could be a dict:
        # {'entry1': {'authors': [{'firstName': 'Harjot', 'lastName': 'Kaur'}]}}
        elif isinstance(res_aux, dict):
            if 'authors' in res_aux:
                for author in res_aux['authors']:
                    authors.append(author)
            else:
                # {'entry1': {'firstName': 'Fadi', 'lastName': 'Aldakheel'}}
                authors.append(res_aux)
        return authors

    def _create_search_prompt(self, author_txt):
        if author_txt == "":
            return ""

        # Read the prompt file content
        user_prompt = self._read_prompt_context()

        combined_prompt = f"{user_prompt} #DATA# {author_txt}"
        return combined_prompt

    def _search_for_author_in_text(self, author_txt):

        combined_prompt = self._create_search_prompt(author_txt)
        # Retry 3 times if not result
        try:
            reply = self.call_llm_api(combined_prompt)
            if "containing the author names" not in reply:
                reply = reply.replace("json", "").replace("`", "")
                # print("\n\n", json.loads(reply), "\n\n")
                return self._adjust_result(json.loads(reply))
            else:
                return []

        except Exception as e:
            print(str(e))
            return []

    def search_for_author_in_text(self, author_txt):

        # Repeat 3 times if not result
        for x in range(3):
            author_result = self._search_for_author_in_text(author_txt)
            print("RES:\n", author_result)
            if len(author_result) > 0:
                if author_result[0].get("firstName", False) or author_result[0].get("lastName", False):
                    return author_result
        # if nothing was find then return the original text in lastName
        return [{'firstName': '', 'lastName': author_txt}]
